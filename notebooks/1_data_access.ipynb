{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: ensure inputs/ hierarchy exists\n",
        "import os\n",
        "os.makedirs(\"inputs/tess\",  exist_ok=True)\n",
        "os.makedirs(\"inputs/harps\", exist_ok=True)\n",
        "print(\"✅ inputs/ folder ready\")\n"
      ],
      "metadata": {
        "id": "NLeE4hmM8Av3",
        "outputId": "fe0f2130-a014-4f24-b899-dfaad7457d9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NLeE4hmM8Av3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'technosignature-pipeline-v2'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 81 (delta 28), reused 23 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (81/81), 28.50 KiB | 2.04 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = (\n",
        "    \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
        "    \"?query=select+pl_name,ra,dec,tic_id+from+pscomppars&format=csv\"\n",
        ")\n",
        "pl = pd.read_csv(url)\n",
        "pl.to_csv(\"inputs/confirmed_planets.csv\", index=False)\n",
        "print(f\"✅ Confirmed planets: {len(pl)} rows\")\n"
      ],
      "metadata": {
        "id": "KDq5iigJQKK1"
      },
      "id": "KDq5iigJQKK1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from astropy.coordinates import SkyCoord\n",
        "import astropy.units as u\n",
        "from astroquery.irsa import Irsa\n",
        "\n",
        "# Output CSV\n",
        "out = \"inputs/wise_photometry.csv\"\n",
        "if os.path.exists(out):\n",
        "    os.remove(out)\n",
        "\n",
        "pl = pd.read_csv(\"inputs/confirmed_planets.csv\")\n",
        "results = []\n",
        "\n",
        "for _, row in pl.iterrows():\n",
        "    coord = SkyCoord(ra=row[\"ra\"]*u.deg, dec=row[\"dec\"]*u.deg, frame=\"icrs\")\n",
        "    try:\n",
        "        tbl = Irsa.query_region(\n",
        "            coord,\n",
        "            catalog=\"allwise_p3as_psd\",\n",
        "            radius=5 * u.arcsec,\n",
        "            columns=[\"ra\",\"dec\",\"w1mpro\",\"w2mpro\"]\n",
        "        )\n",
        "        if len(tbl) > 0:\n",
        "            hit = tbl[0]\n",
        "            w1, w2 = hit[\"w1mpro\"], hit[\"w2mpro\"]\n",
        "            results.append({\n",
        "                \"pl_name\":  row[\"pl_name\"],\n",
        "                \"ra\":        float(hit[\"ra\"]),\n",
        "                \"dec\":       float(hit[\"dec\"]),\n",
        "                \"w1mpro\":    float(w1),\n",
        "                \"w2mpro\":    float(w2),\n",
        "                \"ir_flag\":   bool((w2 - w1) > 0.5)\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"IRSA failed for {row['pl_name']}: {e}\")\n",
        "\n",
        "pd.DataFrame(results).to_csv(out, index=False)\n",
        "print(f\"✅ AllWISE photometry for {len(results)} planets\")\n"
      ],
      "metadata": {
        "id": "ssObBcr3QRHK"
      },
      "id": "ssObBcr3QRHK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Query Pan‑STARRS & SDSS via Vizier around each planet (5″ cone)\n",
        "import pandas as pd\n",
        "from astroquery.vizier import Vizier\n",
        "from astropy.coordinates import SkyCoord\n",
        "import astropy.units as u\n",
        "\n",
        "# allow up to 10 rows per query\n",
        "Vizier.ROW_LIMIT = 10\n",
        "\n",
        "pl = pd.read_csv(\"inputs/confirmed_planets.csv\")\n",
        "ps_results = []\n",
        "sd_results = []\n",
        "\n",
        "for _, row in pl.iterrows():\n",
        "    coord = SkyCoord(ra=row[\"ra\"]*u.deg, dec=row[\"dec\"]*u.deg, frame=\"icrs\")\n",
        "    # Pan-STARRS (PS1) g,r,i\n",
        "    try:\n",
        "        ps = Vizier(columns=[\"gmag\",\"rmag\",\"imag\"], catalog=\"II/349/ps1\").query_region(coord, radius=5*u.arcsec)\n",
        "        if len(ps) > 0:\n",
        "            hit = ps[0][0]  # first match\n",
        "            ps_results.append({\n",
        "                \"pl_name\": row[\"pl_name\"],\n",
        "                \"ra\": float(hit[\"RAJ2000\"]),\n",
        "                \"dec\": float(hit[\"DEJ2000\"]),\n",
        "                \"gmag\": float(hit[\"gmag\"]),\n",
        "                \"rmag\": float(hit[\"rmag\"]),\n",
        "                \"imag\": float(hit[\"imag\"]),\n",
        "                \"ps_flag\": True\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"PS query failed for {row['pl_name']}: {e}\")\n",
        "\n",
        "    # SDSS u,g,r,i,z\n",
        "    try:\n",
        "        sd = Vizier(columns=[\"u\",\"g\",\"r\",\"i\",\"z\"], catalog=\"V/147\").query_region(coord, radius=5*u.arcsec)\n",
        "        if len(sd) > 0:\n",
        "            hit = sd[0][0]\n",
        "            sd_results.append({\n",
        "                \"pl_name\": row[\"pl_name\"],\n",
        "                \"ra\": float(hit[\"RA_ICRS\"]),\n",
        "                \"dec\": float(hit[\"DE_ICRS\"]),\n",
        "                \"u\":  float(hit[\"u\"]),\n",
        "                \"g\":  float(hit[\"g\"]),\n",
        "                \"r\":  float(hit[\"r\"]),\n",
        "                \"i\":  float(hit[\"i\"]),\n",
        "                \"z\":  float(hit[\"z\"]),\n",
        "                \"sdss_flag\": True\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"SDSS query failed for {row['pl_name']}: {e}\")\n",
        "\n",
        "pd.DataFrame(ps_results).to_csv(\"inputs/panstarrs.csv\", index=False)\n",
        "pd.DataFrame(sd_results).to_csv(\"inputs/sdss.csv\",     index=False)\n",
        "print(f\"✅ Pan‑STARRS hits: {len(ps_results)}, SDSS hits: {len(sd_results)}\")\n"
      ],
      "metadata": {
        "id": "ahjWGmSPSMT6"
      },
      "id": "ahjWGmSPSMT6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "# Download\n",
        "url = \"https://public.breakthroughlisten.org/dataset/hits.csv\"\n",
        "bl_csv = \"inputs/bl_hits.csv\"\n",
        "if not os.path.exists(bl_csv):\n",
        "    pd.read_csv(url, nrows=0)  # test URL\n",
        "    !wget -qO inputs/bl_hits.csv {url}\n",
        "\n",
        "# Stream & keep only 1419–1421 MHz\n",
        "out = \"inputs/bl_filtered.csv\"\n",
        "if os.path.exists(out):\n",
        "    os.remove(out)\n",
        "\n",
        "for chunk in pd.read_csv(bl_csv, chunksize=1_000_000):\n",
        "    mask = chunk[\"frequency_mhz\"].between(1419, 1421)\n",
        "    if mask.any():\n",
        "        chunk[mask].to_csv(out, mode=\"a\", index=False,\n",
        "                           header=not os.path.exists(out))\n",
        "    print(f\"Processed {len(chunk)} rows, kept {mask.sum()}\")\n",
        "print(\"✅ Breakthrough Listen filtered\")\n"
      ],
      "metadata": {
        "id": "Fi7LtM9RQUuy"
      },
      "id": "Fi7LtM9RQUuy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from astroquery.mast import Observations\n",
        "import lightkurve as lk\n",
        "from astropy.timeseries import BoxLeastSquares\n",
        "\n",
        "pl = pd.read_csv(\"inputs/confirmed_planets.csv\")\n",
        "flags = []\n",
        "\n",
        "for tic in pl[\"tic_id\"].dropna().unique():\n",
        "    try:\n",
        "        lc = lk.search_lightcurve(f\"TIC {int(tic)}\", mission=\"TESS\").download()\n",
        "        lc_flat = lc.flatten(window_length=401)\n",
        "        bls = BoxLeastSquares(lc_flat.time, lc_flat.flux)\n",
        "        periods = np.linspace(0.5,10,5000)\n",
        "        power = bls.power(periods,0.1).power\n",
        "        depth = bls.depth.max()\n",
        "        snr   = power.max() / np.std(lc_flat.flux)\n",
        "        flags.append({\n",
        "            \"tic_id\":    tic,\n",
        "            \"tess_flag\": bool((depth>0.05) & (snr>20)),\n",
        "            \"tess_period\": float(periods[np.argmax(power)]),\n",
        "            \"tess_snr\":    float(snr)\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"TIC {tic} error: {e}\")\n",
        "\n",
        "pd.DataFrame(flags).to_csv(\"inputs/tess_flags.csv\", index=False)\n",
        "print(f\"✅ TESS flags for {len(flags)} objects\")\n"
      ],
      "metadata": {
        "id": "RxT6zLjCQWr8"
      },
      "id": "RxT6zLjCQWr8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from astroquery.gaia import Gaia\n",
        "import pandas as pd\n",
        "\n",
        "pl = pd.read_csv(\"inputs/confirmed_planets.csv\")\n",
        "gaia_flags = []\n",
        "\n",
        "for _, row in pl.iterrows():\n",
        "    ra,dec = row[\"ra\"], row[\"dec\"]\n",
        "    q = f\"\"\"\n",
        "        SELECT ruwe\n",
        "        FROM gaiaedr3.gaia_source\n",
        "        WHERE CONTAINS(\n",
        "          POINT('ICRS',ra,dec),\n",
        "          CIRCLE('ICRS',{ra},{dec},0.00027778)\n",
        "        )=1 LIMIT 1\n",
        "    \"\"\"\n",
        "    try:\n",
        "        res = Gaia.launch_job(q).get_results().to_pandas()\n",
        "        ruwe = res[\"ruwe\"].iloc[0] if not res.empty else None\n",
        "        gaia_flags.append({\n",
        "            \"pl_name\":  row[\"pl_name\"],\n",
        "            \"gaia_flag\": bool(ruwe and ruwe>1.4),\n",
        "            \"ruwe\":      float(ruwe) if ruwe else None\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Gaia failed for {row['pl_name']}: {e}\")\n",
        "\n",
        "pd.DataFrame(gaia_flags).to_csv(\"inputs/gaia_flags.csv\", index=False)\n",
        "print(f\"✅ Gaia flags for {len(gaia_flags)} planets\")\n"
      ],
      "metadata": {
        "id": "_pIV0DabQYc-"
      },
      "id": "_pIV0DabQYc-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from astroquery.eso import Eso\n",
        "import pandas as pd, glob, os\n",
        "\n",
        "# 1) Retrieve one HARPS dataset (example)\n",
        "eso = Eso()\n",
        "# eso.login()  # if you have ESO credentials\n",
        "prod = eso.query_program(\"HARPS\")[0]\n",
        "eso.retrieve_data(prod, output_dir=\"inputs/harps/\")\n",
        "\n",
        "# 2) Stream all CSVs, flag spikes\n",
        "flags = []\n",
        "for f in glob.glob(\"inputs/harps/*.csv\"):\n",
        "    df = pd.read_csv(f)\n",
        "    spike_count = (df[\"flux\"] > 5*df[\"flux\"].median()).sum()\n",
        "    flags.append({\"file\": os.path.basename(f),\n",
        "                  \"spike_flag\": bool(spike_count>0),\n",
        "                  \"spike_count\": int(spike_count)})\n",
        "pd.DataFrame(flags).to_csv(\"inputs/spec_flags.csv\", index=False)\n",
        "print(f\"✅ HARPS flags for {len(flags)} files\")\n"
      ],
      "metadata": {
        "id": "VJvbPJMwQeKH"
      },
      "id": "VJvbPJMwQeKH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}